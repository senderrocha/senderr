{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Read 100 lines. Lines per second: 7119.46</pre>"
      ],
      "text/plain": [
       "Read 100 lines. Lines per second: 7119.46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ubuntu/coursera-notebooks/course-1/affectivetext_trial.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ubuntu/coursera-notebooks/course-1/affectivetext_trial.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.016339 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.016339 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/ubuntu/coursera-notebooks/course-1/affectivetext_trial.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/ubuntu/coursera-notebooks/course-1/affectivetext_trial.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 250 lines in 0.014269 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 250 lines in 0.014269 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">id</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">headline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Mortar assault leaves at<br>least 18 dead ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Goal delight for Sheva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Nigeria hostage feared<br>dead is freed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Bombers kill shoppers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Vegetables, not fruit,<br>slow brain decline ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">PM: Havana deal a good<br>experiment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Kate is marrying Doherty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">NASA revisiting life on<br>Mars question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Happy birthday, iPod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Alonso would be happy to<br>retire with three titles ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[250 rows x 2 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tid\tint\n",
       "\theadline\tstr\n",
       "\n",
       "Rows: 250\n",
       "\n",
       "Data:\n",
       "+----+-------------------------------+\n",
       "| id |            headline           |\n",
       "+----+-------------------------------+\n",
       "| 1  | Mortar assault leaves at l... |\n",
       "| 2  |     Goal delight for Sheva    |\n",
       "| 3  | Nigeria hostage feared dea... |\n",
       "| 4  |     Bombers kill shoppers     |\n",
       "| 5  | Vegetables, not fruit, slo... |\n",
       "| 6  | PM: Havana deal a good exp... |\n",
       "| 7  |    Kate is marrying Doherty   |\n",
       "| 8  | NASA revisiting life on Ma... |\n",
       "| 9  |      Happy birthday, iPod     |\n",
       "| 10 | Alonso would be happy to r... |\n",
       "+----+-------------------------------+\n",
       "[250 rows x 2 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf=graphlab.SFrame('affectivetext_trial.csv')\n",
    "sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Definindo a função para extração keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals\n",
    "def keywords(data):\n",
    "   \n",
    "    import nltk\n",
    "    import math\n",
    "    from textblob import TextBlob as tb\n",
    "\n",
    "    \n",
    "    #Removendo pontuacoes \n",
    "    import string\n",
    "    string.punctuation\n",
    "    sent = data\n",
    "    data1=\" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in sent]).split())\n",
    "    \n",
    "    #Removendo stopwords\n",
    "    from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    nltk.download('stopwords')\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    words = word_tokenize(data1)\n",
    "    wordsFiltered = []\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)     \n",
    "    data2=wordsFiltered\n",
    "    \n",
    "    #Juntando o texto Filtrado\n",
    "    data3=\" \".join(data2)\n",
    "    import pip\n",
    "    package_name='senticnet'\n",
    "    pip.main(['install', package_name])\n",
    "    \n",
    "    #TF-IDF ANALISE\n",
    "    import pip\n",
    "    package_name='textblob'\n",
    "    pip.main(['install', package_name])\n",
    "    #import math\n",
    "    #from textblob import TextBlob as tb\n",
    "    #from __future__ import division, unicode_literals\n",
    "    def tf(word, blob):\n",
    "        return blob.words.count(word) / len(blob.words)\n",
    "    def n_containing(word, bloblist):\n",
    "        return sum(1 for blob in bloblist if word in blob.words)\n",
    "\n",
    "    def idf(word, bloblist):\n",
    "        return math.log(len(bloblist) / (1 + n_containing(word, bloblist)))\n",
    "\n",
    "    def tfidf(word, blob, bloblist):\n",
    "        return tf(word, blob) * idf(word, bloblist)\n",
    "    document1 = tb(data3)\n",
    "    bloblist = [document1]\n",
    "    for i, blob in enumerate(bloblist):\n",
    "        print(\"Top words in document {}\".format(i + 1))\n",
    "        scores = {word: tfidf(word, blob, bloblist) for word in blob.words}\n",
    "        sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        #for word, score in sorted_words[:3]:\n",
    "         #   print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))\n",
    "           \n",
    "        y=sorted_words\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loop para análise de sentimento de cada texto  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Requirement already satisfied (use --upgrade to upgrade): senticnet in /opt/anaconda/anaconda2/lib/python2.7/site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): textblob in /opt/anaconda/anaconda2/lib/python2.7/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): nltk>=3.1 in /opt/anaconda/anaconda2/lib/python2.7/site-packages (from textblob)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'Mortar', -0.11552453009332421),\n",
       " (u'leaves', -0.11552453009332421),\n",
       " (u'dead', -0.11552453009332421),\n",
       " (u'assault', -0.11552453009332421),\n",
       " (u'least', -0.11552453009332421),\n",
       " (u'18', -0.11552453009332421)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=sf[0]['headline']\n",
    "wordss=keywords(data)\n",
    "wordss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#fear', '#disgust']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extraindo sentimento de cada keyword\n",
    "from senticnet.senticnet import Senticnet\n",
    "sn = Senticnet()\n",
    "#moodtags=sn.moodtags('new')\n",
    "d='mortar'\n",
    "#concept_info = sn.sentics(d)\n",
    "concept_info = sn.moodtags(d)\n",
    "y=concept_info\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
